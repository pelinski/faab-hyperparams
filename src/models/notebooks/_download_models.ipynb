{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pelinski/Dropbox/phd/projects/faab/.venv/lib/python3.10/site-packages/wandb/sdk/launch/builder/build.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "import json\n",
        "import os, sys\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir)))\n",
        "from utils import _scale_params, load_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "api = wandb.Api()\n",
        "api.entity = \"faab-hyperparams\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "sweep_ids = [\"tonczgio\",\n",
        "\"llctcl68\",\n",
        "\"e33s48ug\",\n",
        "\"tmuf8nz6\",\n",
        "\"shen1jqe\",\n",
        "\"12ie0tmu\",\n",
        "\"f8ayvluc\",\n",
        "\"7cl8otxa\",\n",
        "\"rxqbfbtd\",\n",
        "\"p0cx9m4p\"]\n",
        "sweeps = [api.sweep(f'faab-hyperparams/faab_autoencoder_minidataset/{sweep}') for sweep in sweep_ids]\n",
        "_path = \"../trained/transformer-minidataset\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# finished_runs = []\n",
        "\n",
        "# # Iterate over runs in the sweep\n",
        "# for run in sweep.runs:\n",
        "#     # Fetch the run to get detailed information, including its state\n",
        "#     detailed_run = wandb.Api().run(f\"{run.project}/{run.id}\")\n",
        "#     # Check if the run is finished\n",
        "#     if detailed_run.state == \"finished\":\n",
        "#         finished_runs.append(detailed_run)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# #load api key from .env\n",
        "# with open(\"../.env\") as f:\n",
        "#     for line in f:\n",
        "#         if line.strip() and not line.startswith('#'):\n",
        "#             key, value = line.strip().split('=', 1)\n",
        "#             os.environ[key] = value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wandb.login(key=os.environ[\"WANDB_API_KEY\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bqgct1xf 75\n",
            "8ci602ed 75\n",
            "wy9m78x6 75\n",
            "qqf3nym9 75\n",
            "42jy2fxw 75\n",
            "cco08cwt 75\n",
            "rj02z1yf 75\n",
            "5h6gpgli 75\n",
            "wecyjjv6 75\n",
            "a9wnfeis 75\n",
            "guca3j3n 75\n",
            "zte64g1k 75\n",
            "d4p9psev 75\n",
            "i9m7wsct 75\n",
            "5qndphh8 75\n",
            "5k1838fm 75\n",
            "x83w54gk 75\n",
            "i8dajq5v 75\n",
            "rarx6o1s 75\n",
            "l8wab3qb 75\n",
            "f0i9vau9 75\n",
            "j9980erp 75\n",
            "9b58xj1e 75\n",
            "qfqaf3a0 75\n",
            "96rsdi7g 75\n",
            "hujc76vx 75\n",
            "goylnvgv 25\n",
            "mh9u1uwt 75\n",
            "z4q6c7dy 75\n",
            "j1kfzisy 75\n",
            "cgy6m30d 75\n",
            "ljwe16mw 75\n",
            "kk5b7b44 75\n",
            "0lhbjjox 75\n",
            "r2r9n709 75\n",
            "b4gmn89t 75\n",
            "yub5cwga 75\n",
            "jq8ts7qg 75\n",
            "4hwr1dmc 75\n",
            "qdrpgjv7 75\n",
            "4eyhw9l5 75\n",
            "jw8cws22 75\n",
            "pbok65yh 75\n",
            "21soegq8 75\n",
            "243x9axq 75\n",
            "2b9nn4w4 75\n",
            "wctedkaq 75\n",
            "zpiylfsf 75\n",
            "9f85pw8o 75\n",
            "e251ayzv 75\n",
            "tmq9segx 75\n",
            "g85pwm7w 75\n",
            "sh3yox5o 75\n",
            "4kpv5ny6 75\n",
            "eqgrcsfz 75\n",
            "089qtbq9 75\n",
            "xzkrrlon 75\n",
            "1qvcwtuy 75\n",
            "h98zxhqo 75\n",
            "3ciea2fd 75\n",
            "wwyb5emc 75\n",
            "5d97cdth 75\n",
            "49a2ejsd 75\n",
            "1vfuf4yf 75\n",
            "9j4b7ykt 75\n",
            "vfq0mqr2 75\n",
            "e2gt57qi 75\n",
            "2eg5lihp 75\n",
            "b70ksuej 75\n",
            "8zn32fpo 75\n",
            "5yvxxehz 75\n",
            "d28qmw4p 50\n",
            "9ex6w4o7 50\n",
            "7a75g94k 75\n",
            "pr6zwy0y 75\n",
            "x335qqnn 75\n",
            "ppde8iak 75\n",
            "ionnpajj 75\n",
            "bhtqerw4 75\n",
            "ov2quu9v 75\n",
            "2ovhhhq4 75\n",
            "xh2luxo1 75\n",
            "hmemhukc 75\n",
            "xoa9cg2v 75\n",
            "p6h9ijhc 75\n",
            "r13a9fn1 75\n",
            "35ake2xb 75\n",
            "gumfyen4 75\n",
            "zdjv45vf 75\n",
            "276hsm9x 75\n",
            "tbimy590 75\n",
            "6x0qe2m1 75\n",
            "jwee0ui6 75\n",
            "tkfauz2a 75\n",
            "oecc54ca 75\n",
            "pqrz8ov0 75\n",
            "ief6qlpa 75\n",
            "nv4k35f8 75\n",
            "tb41kyc7 75\n",
            "xt1b5ncs 75\n",
            "haf2bh4y 75\n",
            "x086wfiq 75\n",
            "7jek9blg 75\n",
            "wpjuorrv 75\n",
            "tcsffrxh 75\n",
            "f862mtsz 75\n",
            "nc5dg8mw 75\n",
            "ama4yp3c 75\n",
            "c03toca7 75\n",
            "hkl9wwx2 75\n",
            "u3gpoeb5 75\n",
            "kdfu69md 75\n",
            "bq6yxel9 75\n",
            "2o81rurl 75\n",
            "eh1ofo18 75\n",
            "7yq24a6n 75\n",
            "kaq2rk3k 25\n",
            "7v0kl2ys 75\n",
            "alyrx2up 75\n",
            "v3ecgdrc 75\n",
            "rlx8q7wd 75\n",
            "ig61duyp 75\n",
            "56lvlmuj 75\n",
            "gza0sltm 75\n",
            "lqaq5o7t 50\n",
            "9r1c9fln 75\n",
            "c3xau2c1 75\n",
            "nyu2e6ch 75\n",
            "luy9gglx 75\n",
            "pmfd5svl 50\n",
            "9ymuwtf3 75\n",
            "dg7kkgd8 75\n",
            "9jwusq5z 75\n",
            "7bwk65rx 75\n",
            "fuh282us 75\n",
            "pgfdsbz0 75\n",
            "rougwg7n 75\n",
            "a8puqmfo 75\n",
            "lelropxs 75\n",
            "4inzi6jb 75\n",
            "r21hwu9p 75\n",
            "1kr3jr21 75\n",
            "7f4fvk0u 75\n",
            "pqs2o3hf 75\n",
            "yicubzho 75\n",
            "oieua62y 50\n",
            "7ht70vlg 75\n",
            "2matqs0f 75\n",
            "100qjyxs 75\n",
            "q37m37uz 75\n",
            "29eu19bm 75\n",
            "ce57u94g 75\n",
            "n7vo46q6 75\n",
            "8wzblws2 75\n",
            "5e45aurd 75\n",
            "9j2ihtkh 75\n",
            "9643pivy 75\n",
            "lqol8fmo 75\n",
            "2s5lgg5h 75\n",
            "ek93v82t 75\n",
            "8ngt4hwg 75\n",
            "e7pccu76 75\n",
            "kts1h5xf 75\n",
            "cy68rqaa 75\n",
            "lanxs1z0 75\n",
            "8u7zo5fd 75\n",
            "7wvj11dh 75\n",
            "0s44sabe 75\n",
            "rjmpj54w 75\n",
            "h5km9t5p 75\n",
            "lrubl0th 75\n",
            "j085j3tr 75\n",
            "qbtxax27 75\n",
            "m8ceddvv 75\n",
            "u9xd4jpq 75\n",
            "rm316933 25\n",
            "k4un2seg 50\n",
            "aku0py72 50\n",
            "16agieiu 100\n",
            "qbbqzxsu 25\n",
            "me1o4o0n 75\n",
            "w7d0ciiv 75\n",
            "i6fkj020 75\n",
            "wppepbmy 75\n",
            "xjfqwbn9 75\n",
            "p0xrdbhn 75\n",
            "50hxrq1u 75\n",
            "lxg480rf 75\n",
            "tlrvv08t 75\n",
            "7gxqitbr 75\n",
            "vngul0kg 75\n",
            "2uuu2iq0 75\n",
            "mq4vvlcw 75\n",
            "dsnjplbm 75\n",
            "vr6thcmm 75\n",
            "rwt0td37 75\n",
            "1ez3zta2 75\n",
            "3egjreh5 75\n",
            "x46ov0fl 75\n",
            "8qrn7lg1 75\n",
            "4p4hyduk 50\n",
            "awaen0te 150\n",
            "v0i1bb6l 25\n",
            "qva04qmf 100\n"
          ]
        }
      ],
      "source": [
        "id_ep = {}\n",
        "run_ids = []\n",
        "for sweep in sweeps:\n",
        "    for run in sweep.runs:\n",
        "        files = [file.name for file in run.files()]\n",
        "        matching_files = [file for file in files if file.endswith(\".model\")]\n",
        "        epochs = [int(file.split(\"_\")[-1].split(\".model\")[0]) for file in matching_files]\n",
        "        if epochs == []:\n",
        "            continue\n",
        "        highest_epoch = max(epochs)\n",
        "        id_ep[run.id] = highest_epoch\n",
        "        run_ids.append(run.id)\n",
        "        print(run.id, highest_epoch)    \n",
        "        root_file_name = f'transformer_run_{run.id}_{highest_epoch}'\n",
        "        run.file(f'{root_file_name}.model').download(root=_path, exist_ok=True)\n",
        "        json.dump(run.config, open(f'{_path}/{root_file_name}.json', \"w\"))\n",
        "        json.dump({\"train_loss\": run.summary[\"train_loss\"]}, open(f'{_path}/{root_file_name}_metrics.json', \"w\"))\n",
        "\n",
        "json.dump(run_ids, open(f'{_path}/run_ids.json', \"w\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "_path = \"../trained/transformer-minidataset\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "json.dump(id_ep, open(f'{_path}/id_ep.json', \"w\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "_train_losses = {}\n",
        "for _id in run_ids:\n",
        "    _train_losses[_id] = json.load(open(f'{_path}/transformer_run_{_id}_{id_ep[_id]}_metrics.json'))[\"train_loss\"]\n",
        "\n",
        "models_ordered_by_asc_loss = list(dict(sorted(_train_losses.items(), key=lambda item: item[1])).keys())\n",
        "filename = _path + \"/models_ordered_by_asc_loss.json\"\n",
        "\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(models_ordered_by_asc_loss, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load id_ep\n",
        "id_ep = json.load(open(f'{_path}/id_ep.json'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaled_model_coordinates = _scale_params(epochs=id_ep, path = _path)\n",
        "\n",
        "filename = _path + \"/scaled_params.json\"\n",
        "with open (filename, 'w') as file:\n",
        "    json.dump(scaled_model_coordinates, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_configs = {}\n",
        "run_ids = json.load(open(f'{_path}/run_ids.json'))\n",
        "for run in run_ids:\n",
        "    config = load_config(run, epochs=id_ep[run],path=_path)\n",
        "    all_configs[run] = config\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bqgct1xf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2855777170478696,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00023275188241908096,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8ci602ed': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10540070160110164,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0001804393391736403,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'wy9m78x6': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18910527613671088,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00028993994130578925,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'qqf3nym9': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23072310110904157,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0007280542931750218,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '42jy2fxw': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2271637532706375,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005001854235076788,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'cco08cwt': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10920298523296952,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00020569568821805328,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rj02z1yf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2410789483779626,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00027019846913553525,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '5h6gpgli': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1624937372669271,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005515564159669217,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'wecyjjv6': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.12165793766327744,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 2.624521744535302e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'a9wnfeis': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.281494485649355,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00031437167295699756,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'guca3j3n': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26229187338050974,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0008098454670914209,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'zte64g1k': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27918124479243694,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 3.828250038614256e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'd4p9psev': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.29014464832722975,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 8.227779887744424e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'i9m7wsct': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2190590176500069,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0006892527727767787,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '5qndphh8': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26977887181479965,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0003328910981298875,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '5k1838fm': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2102847141288242,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0003590846718825117,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'x83w54gk': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.24073023149735348,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0002122481614549261,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'i8dajq5v': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2124777688532085,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00084479529694818,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rarx6o1s': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10968605617482396,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 6.80846548408176e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'l8wab3qb': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2096805557152353,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00036996457098298943,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'f0i9vau9': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.22609870036334195,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0008459027188841369,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'j9980erp': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.16778042731234585,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.000713162206287676,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9b58xj1e': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14278093743359124,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.000904900957348536,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'qfqaf3a0': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1253089822259679,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00014787951047013227,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '96rsdi7g': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27460958682343506,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.000523206144809928,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'hujc76vx': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23958162722694415,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0004773487772329329,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'goylnvgv': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.20162523858254727,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00018021069219075405,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'mh9u1uwt': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2054540425059111,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.000414468514816319,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'z4q6c7dy': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2902693874735447,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0007882728076572671,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'j1kfzisy': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.29571266328419177,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0001866023675657721,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'cgy6m30d': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14812843086427016,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00011629737814928408,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ljwe16mw': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2392611100026868,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0009826664871712644,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'kk5b7b44': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.22649789557034097,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00026436333672379207,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '0lhbjjox': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.164659943808605,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00041478265448183574,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'r2r9n709': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13922245659212282,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00040543467152501136,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'b4gmn89t': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1650747432066701,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0008813451433757157,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'yub5cwga': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.16951385434659053,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 8.123986410583239e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'jq8ts7qg': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.24385364150407576,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0007687709980175855,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '4hwr1dmc': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27966115761942356,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0009449406016509952,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'qdrpgjv7': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1046352087076702,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0008500735968568783,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '4eyhw9l5': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.25999050042259264,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0005251582272113012,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'jw8cws22': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2083881333125987,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0003534712453605632,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'pbok65yh': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2747157611922574,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00011978331879214244,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '21soegq8': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1652222270107323,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0006979082986563552,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '243x9axq': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2894780294102375,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00044862018127496287,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2b9nn4w4': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.163787710840284,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0007964559863284705,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'wctedkaq': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1010975416939248,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0001472733091801861,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'zpiylfsf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1744748128720114,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0008128227924736749,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9f85pw8o': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2676699721628153,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0003242818942694927,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'e251ayzv': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2186961622087612,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0009360630423114544,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'tmq9segx': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.22931983546658408,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0006540753077665666,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'g85pwm7w': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18659066204981353,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0003937096518506388,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'sh3yox5o': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.29524809561790444,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0004454369879297589,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '4kpv5ny6': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.29589801618007455,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0009040289996421004,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'eqgrcsfz': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2547779515938834,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0007836924979508665,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '089qtbq9': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27125269383151496,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0006052318035653062,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'xzkrrlon': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1334689439659376,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00025855513315482126,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '1qvcwtuy': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.12509828774215542,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0003198821437619932,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'h98zxhqo': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.15352031517800593,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0007621224469965891,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '3ciea2fd': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1845217340091076,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0002770404502725881,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'wwyb5emc': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.266388634527876,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0005491396500881296,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '5d97cdth': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14757408224890226,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0004987990568270526,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '49a2ejsd': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.221633233363554,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0009810805739615066,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '1vfuf4yf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18654431000074245,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0002781504717902271,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9j4b7ykt': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27660600706155947,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0001809531239386272,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'vfq0mqr2': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1556050426973739,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0005997745538083866,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'e2gt57qi': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2859593326171173,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0005429071784139717,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2eg5lihp': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2855869039450923,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0007076081211046031,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'b70ksuej': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.28422403618656955,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0006078728392475534,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8zn32fpo': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2130823860847555,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.000994632410471608,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '5yvxxehz': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10929341998589608,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0005667482198413728,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'd28qmw4p': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1649723958403323,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0003781223337587643,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9ex6w4o7': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13315109283172674,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0008369620210660304,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7a75g94k': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.191780405573684,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0008751769661561027,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'pr6zwy0y': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.19786885227072665,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0009010819240245352,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'x335qqnn': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1273380633893333,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.000967062013633121,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ppde8iak': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.16595151203996955,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 8.649108447954391e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ionnpajj': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26091180884041576,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.00039872100898570464,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'bhtqerw4': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.15662403399474578,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 3.60931725091036e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ov2quu9v': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2609125569675459,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0005618769154579035,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2ovhhhq4': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17913811575551702,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004227379983969216,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'xh2luxo1': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26836534508802556,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0007974882287025394,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'hmemhukc': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1369417818189768,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0008236436371404679,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'xoa9cg2v': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.29410235317321287,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004589632905919933,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'p6h9ijhc': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23490162006674473,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.00022095574735435456,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'r13a9fn1': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26213764427201247,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004334069308940235,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '35ake2xb': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17663288005706723,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0002464653629960717,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'gumfyen4': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18713219750001076,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0007812720799121441,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'zdjv45vf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23129739659227688,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0009396160955270308,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '276hsm9x': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.11285903783216795,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0009373941539659966,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'tbimy590': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.21409922353861432,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0006065865498481971,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '6x0qe2m1': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2991761525380944,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.00047738718039547456,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'jwee0ui6': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13413017598566418,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0008416833458542834,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'tkfauz2a': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17208275398349043,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0003702765371375005,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'oecc54ca': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.196308941064681,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004014651096396554,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'pqrz8ov0': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.11855857495938796,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0007926852844017763,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ief6qlpa': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2591598651479804,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.00021460617824494175,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'nv4k35f8': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1830176755260438,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0009240491621464182,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'tb41kyc7': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2609617671120289,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0006909567091496974,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'xt1b5ncs': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10176704107798908,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0009483507618622448,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'haf2bh4y': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.11371641871882776,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.00011075619922356204,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'x086wfiq': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1191663434761813,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.000401901810193344,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7jek9blg': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.195847051365859,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004232811127050189,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'wpjuorrv': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2985736307976472,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0003340522451361766,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'tcsffrxh': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26390440185540676,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0008348489623844455,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'f862mtsz': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.29433901214620384,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0003392637219016389,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'nc5dg8mw': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10097491675440153,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0006129258538911982,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ama4yp3c': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.16957814779781122,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004363435461964672,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'c03toca7': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1489769701437633,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0009739628460496764,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'hkl9wwx2': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1469985609790625,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 9.853157788086776e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'u3gpoeb5': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2510187680619836,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.000708176967982951,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'kdfu69md': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2024716393376072,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004611375207186027,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'bq6yxel9': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18604899505516104,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 7.093890899241284e-06,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2o81rurl': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1530172638527704,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 1.1170097422019689e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'eh1ofo18': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.20857816325647355,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0007194523447559027,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7yq24a6n': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.19364015317277744,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004057829586230827,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'kaq2rk3k': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.28929514785725474,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007199789395618475,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7v0kl2ys': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17576533723054946,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00014206262301631734,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'alyrx2up': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2894315297122415,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0006643743026918484,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'v3ecgdrc': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13585739025509405,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.000340878099677853,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rlx8q7wd': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.12026903116405392,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0009573344774526804,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ig61duyp': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2187672649036715,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0006090994682044524,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '56lvlmuj': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2992539827180275,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00018716231467293988,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'gza0sltm': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.24224836511583497,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00021385415426870057,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'lqaq5o7t': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14587085912974238,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00014597217815201836,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9r1c9fln': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.15813732687535909,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008802275771325066,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'c3xau2c1': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2771565929300287,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007934394568723956,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'nyu2e6ch': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17665609791335982,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0009087041952862956,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'luy9gglx': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10100917973021202,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00095080609602275,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'pmfd5svl': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17910288076473635,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00033824341304998886,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9ymuwtf3': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17116049888181414,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0003815336670243346,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'dg7kkgd8': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18964416002552317,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0004887759710763173,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9jwusq5z': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.20683417779680272,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007573898073058938,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7bwk65rx': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2599990945500502,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0009246046736333366,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'fuh282us': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23430625844030328,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00030438792373795476,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'pgfdsbz0': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.250765328919428,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008430732070232518,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rougwg7n': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.12727538742071162,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0005533359379773176,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'a8puqmfo': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27027374217252376,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007116599143556817,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'lelropxs': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1625034473967126,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0003596052646306811,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '4inzi6jb': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14861530065452483,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007371906117713183,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'r21hwu9p': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.20122904693539617,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00027630605530481155,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '1kr3jr21': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.28569661399314705,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0009725742667354236,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7f4fvk0u': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27327634221134867,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0003542170599642075,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'pqs2o3hf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 80,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.191025532586868,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0006283507474504267,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'yicubzho': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2914184256950586,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0006168398482204149,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'oieua62y': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.21120024573121093,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008596489897710801,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7ht70vlg': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23855171318587853,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00024264423233795452,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2matqs0f': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1032038833677,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0005105525061353309,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '100qjyxs': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1017308949425268,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 2.5361723483315e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'q37m37uz': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17524914841752534,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 1.3224017058944826e-06,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '29eu19bm': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.15659396897547273,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008605323500080865,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ce57u94g': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1316016734592294,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008355947531424496,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'n7vo46q6': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2050536116756755,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007701338458152773,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8wzblws2': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1614514831945373,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00022227307120067095,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '5e45aurd': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14393311221855826,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0005150403707110832,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9j2ihtkh': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13629631126661773,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007214244469720608,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9643pivy': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.239449652988266,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00037080989712884825,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'lqol8fmo': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2346408451678245,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00082910560695628,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2s5lgg5h': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2433234931720276,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00027404127921832835,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ek93v82t': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.16049795058360808,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.000493177039682876,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8ngt4hwg': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17977818443123902,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00029739226013204704,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'e7pccu76': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1903007943539346,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008716143970294984,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'kts1h5xf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13516030384111574,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0004024328542269946,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'cy68rqaa': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2898902606961598,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0006370559391156643,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'lanxs1z0': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1314181874057887,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0002475844212798116,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8u7zo5fd': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.16406696781765723,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007334045238873742,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7wvj11dh': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2202738001564549,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0009838889880744756,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '0s44sabe': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.21275557175368104,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0002826832772802751,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rjmpj54w': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2643072751567912,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00032456241476059276,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'h5km9t5p': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2917229897239493,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0006212872548234598,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'lrubl0th': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1588466270932432,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008304901352555321,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'j085j3tr': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2849278818171441,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0009571848825636564,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'qbtxax27': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.11623049283371788,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0002180525476701356,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'm8ceddvv': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1770592064657544,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0003380683887626883,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'u9xd4jpq': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 80,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1760438249109487,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0004414024720606596,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rm316933': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10571859201372308,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0008259333425271607,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'k4un2seg': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18812788834736385,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.00051500095746108,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'aku0py72': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2076909937956049,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00034162363884589355,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '16agieiu': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18138908332735712,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0004982693386230584,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'qbbqzxsu': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27706474417368054,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0002539011069356524,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'me1o4o0n': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1693490632915518,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0002764143272495516,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'w7d0ciiv': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23421827686253152,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 5.742642272325027e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'i6fkj020': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.22890345587004424,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0003913128602389038,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'wppepbmy': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2945095590429705,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0009135889104694108,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'xjfqwbn9': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14634910834286508,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00010912928357494545,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'p0xrdbhn': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2655889791454583,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0006957714498345671,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '50hxrq1u': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.169642513424277,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0007981702875390946,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'lxg480rf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.25420508119670215,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005201742278771364,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'tlrvv08t': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.15078067439019666,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0006018700347437111,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7gxqitbr': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.287130889151688,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005303454176533573,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'vngul0kg': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1549910452098978,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 9.06714355577043e-06,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2uuu2iq0': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2793781212425423,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005619317552080827,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'mq4vvlcw': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.21337755742988285,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 2.244558761331017e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'dsnjplbm': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2568403188811882,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005669728772313863,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'vr6thcmm': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.11330632166616342,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0002189220067769845,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rwt0td37': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.20216059241475423,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00060253591944403,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '1ez3zta2': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18031505974553264,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0009117736297076736,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '3egjreh5': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13811466718213597,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005525510241206019,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'x46ov0fl': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23280820130427465,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 5.3565774169448965e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8qrn7lg1': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2019862093594661,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00035589368188430003,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '4p4hyduk': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.11534111592003808,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.000508803782195644,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'awaen0te': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1868305731830645,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0008827722112012347,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'v0i1bb6l': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.253375628304945,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008481797083061749,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'qva04qmf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2082541743548858,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00047090399635498094,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0}}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "204"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(run_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bqgct1xf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2855777170478696,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00023275188241908096,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8ci602ed': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10540070160110164,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0001804393391736403,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'wy9m78x6': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18910527613671088,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00028993994130578925,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'qqf3nym9': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23072310110904157,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0007280542931750218,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '42jy2fxw': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2271637532706375,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005001854235076788,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'cco08cwt': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10920298523296952,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00020569568821805328,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rj02z1yf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2410789483779626,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00027019846913553525,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '5h6gpgli': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1624937372669271,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005515564159669217,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'wecyjjv6': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.12165793766327744,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 2.624521744535302e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'a9wnfeis': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.281494485649355,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00031437167295699756,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'guca3j3n': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26229187338050974,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0008098454670914209,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'zte64g1k': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27918124479243694,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 3.828250038614256e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'd4p9psev': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.29014464832722975,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 8.227779887744424e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'i9m7wsct': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2190590176500069,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0006892527727767787,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '5qndphh8': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26977887181479965,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0003328910981298875,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '5k1838fm': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2102847141288242,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0003590846718825117,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'x83w54gk': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.24073023149735348,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0002122481614549261,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'i8dajq5v': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2124777688532085,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00084479529694818,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rarx6o1s': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10968605617482396,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 6.80846548408176e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'l8wab3qb': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2096805557152353,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00036996457098298943,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'f0i9vau9': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.22609870036334195,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0008459027188841369,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'j9980erp': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.16778042731234585,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.000713162206287676,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9b58xj1e': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14278093743359124,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.000904900957348536,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'qfqaf3a0': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1253089822259679,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00014787951047013227,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '96rsdi7g': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27460958682343506,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.000523206144809928,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'hujc76vx': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23958162722694415,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0004773487772329329,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'goylnvgv': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.20162523858254727,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00018021069219075405,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'mh9u1uwt': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2054540425059111,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.000414468514816319,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'z4q6c7dy': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2902693874735447,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0007882728076572671,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'j1kfzisy': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.29571266328419177,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0001866023675657721,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'cgy6m30d': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14812843086427016,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00011629737814928408,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ljwe16mw': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2392611100026868,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0009826664871712644,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'kk5b7b44': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.22649789557034097,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00026436333672379207,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '0lhbjjox': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.164659943808605,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00041478265448183574,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'r2r9n709': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13922245659212282,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00040543467152501136,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'b4gmn89t': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1650747432066701,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0008813451433757157,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'yub5cwga': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.16951385434659053,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 8.123986410583239e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'jq8ts7qg': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.24385364150407576,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0007687709980175855,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '4hwr1dmc': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27966115761942356,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0009449406016509952,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'qdrpgjv7': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1046352087076702,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0008500735968568783,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '4eyhw9l5': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.25999050042259264,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0005251582272113012,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'jw8cws22': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2083881333125987,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0003534712453605632,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'pbok65yh': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2747157611922574,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00011978331879214244,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '21soegq8': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1652222270107323,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0006979082986563552,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '243x9axq': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2894780294102375,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00044862018127496287,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2b9nn4w4': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.163787710840284,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0007964559863284705,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'wctedkaq': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1010975416939248,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0001472733091801861,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'zpiylfsf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1744748128720114,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0008128227924736749,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9f85pw8o': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2676699721628153,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0003242818942694927,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'e251ayzv': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2186961622087612,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0009360630423114544,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'tmq9segx': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.22931983546658408,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0006540753077665666,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'g85pwm7w': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18659066204981353,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0003937096518506388,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'sh3yox5o': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.29524809561790444,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0004454369879297589,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '4kpv5ny6': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.29589801618007455,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0009040289996421004,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'eqgrcsfz': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2547779515938834,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0007836924979508665,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '089qtbq9': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27125269383151496,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0006052318035653062,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'xzkrrlon': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1334689439659376,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00025855513315482126,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '1qvcwtuy': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.12509828774215542,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0003198821437619932,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'h98zxhqo': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.15352031517800593,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0007621224469965891,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '3ciea2fd': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1845217340091076,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0002770404502725881,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'wwyb5emc': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.266388634527876,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0005491396500881296,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '5d97cdth': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14757408224890226,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0004987990568270526,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '49a2ejsd': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.221633233363554,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0009810805739615066,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '1vfuf4yf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18654431000074245,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0002781504717902271,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9j4b7ykt': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27660600706155947,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0001809531239386272,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'vfq0mqr2': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1556050426973739,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0005997745538083866,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'e2gt57qi': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2859593326171173,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0005429071784139717,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2eg5lihp': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2855869039450923,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0007076081211046031,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'b70ksuej': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.28422403618656955,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0006078728392475534,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8zn32fpo': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2130823860847555,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.000994632410471608,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '5yvxxehz': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10929341998589608,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0005667482198413728,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'd28qmw4p': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1649723958403323,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0003781223337587643,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9ex6w4o7': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13315109283172674,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0008369620210660304,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7a75g94k': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.191780405573684,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0008751769661561027,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'pr6zwy0y': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.19786885227072665,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0009010819240245352,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'x335qqnn': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1273380633893333,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.000967062013633121,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ppde8iak': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.16595151203996955,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 8.649108447954391e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ionnpajj': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26091180884041576,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.00039872100898570464,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'bhtqerw4': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.15662403399474578,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 3.60931725091036e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ov2quu9v': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2609125569675459,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0005618769154579035,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2ovhhhq4': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17913811575551702,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004227379983969216,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'xh2luxo1': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26836534508802556,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0007974882287025394,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'hmemhukc': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1369417818189768,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0008236436371404679,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'xoa9cg2v': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.29410235317321287,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004589632905919933,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'p6h9ijhc': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23490162006674473,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.00022095574735435456,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'r13a9fn1': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26213764427201247,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004334069308940235,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '35ake2xb': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17663288005706723,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0002464653629960717,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'gumfyen4': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18713219750001076,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0007812720799121441,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'zdjv45vf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23129739659227688,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0009396160955270308,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '276hsm9x': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.11285903783216795,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0009373941539659966,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'tbimy590': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.21409922353861432,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0006065865498481971,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '6x0qe2m1': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2991761525380944,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.00047738718039547456,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'jwee0ui6': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13413017598566418,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0008416833458542834,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'tkfauz2a': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17208275398349043,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0003702765371375005,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'oecc54ca': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.196308941064681,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004014651096396554,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'pqrz8ov0': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.11855857495938796,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0007926852844017763,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ief6qlpa': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2591598651479804,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.00021460617824494175,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'nv4k35f8': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1830176755260438,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0009240491621464182,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'tb41kyc7': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2609617671120289,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0006909567091496974,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'xt1b5ncs': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10176704107798908,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0009483507618622448,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'haf2bh4y': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.11371641871882776,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.00011075619922356204,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'x086wfiq': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1191663434761813,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.000401901810193344,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7jek9blg': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.195847051365859,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004232811127050189,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'wpjuorrv': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2985736307976472,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0003340522451361766,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'tcsffrxh': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26390440185540676,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0008348489623844455,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'f862mtsz': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.29433901214620384,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0003392637219016389,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'nc5dg8mw': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10097491675440153,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0006129258538911982,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ama4yp3c': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.16957814779781122,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004363435461964672,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'c03toca7': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1489769701437633,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0009739628460496764,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'hkl9wwx2': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1469985609790625,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 9.853157788086776e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'u3gpoeb5': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2510187680619836,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.000708176967982951,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'kdfu69md': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2024716393376072,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004611375207186027,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'bq6yxel9': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18604899505516104,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 7.093890899241284e-06,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2o81rurl': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1530172638527704,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 1.1170097422019689e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'eh1ofo18': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.20857816325647355,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0007194523447559027,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7yq24a6n': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.19364015317277744,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0004057829586230827,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'kaq2rk3k': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.28929514785725474,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007199789395618475,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7v0kl2ys': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17576533723054946,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00014206262301631734,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'alyrx2up': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2894315297122415,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0006643743026918484,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'v3ecgdrc': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13585739025509405,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.000340878099677853,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rlx8q7wd': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.12026903116405392,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0009573344774526804,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ig61duyp': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2187672649036715,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0006090994682044524,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '56lvlmuj': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2992539827180275,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00018716231467293988,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'gza0sltm': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.24224836511583497,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00021385415426870057,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'lqaq5o7t': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14587085912974238,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00014597217815201836,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9r1c9fln': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.15813732687535909,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008802275771325066,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'c3xau2c1': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2771565929300287,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007934394568723956,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'nyu2e6ch': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17665609791335982,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0009087041952862956,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'luy9gglx': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10100917973021202,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00095080609602275,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'pmfd5svl': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17910288076473635,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00033824341304998886,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9ymuwtf3': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17116049888181414,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0003815336670243346,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'dg7kkgd8': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18964416002552317,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0004887759710763173,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9jwusq5z': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.20683417779680272,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007573898073058938,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7bwk65rx': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2599990945500502,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0009246046736333366,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'fuh282us': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23430625844030328,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00030438792373795476,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'pgfdsbz0': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.250765328919428,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008430732070232518,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rougwg7n': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.12727538742071162,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0005533359379773176,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'a8puqmfo': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27027374217252376,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007116599143556817,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'lelropxs': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1625034473967126,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0003596052646306811,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '4inzi6jb': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14861530065452483,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007371906117713183,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'r21hwu9p': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.20122904693539617,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00027630605530481155,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '1kr3jr21': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.28569661399314705,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0009725742667354236,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7f4fvk0u': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27327634221134867,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0003542170599642075,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'pqs2o3hf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 80,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.191025532586868,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0006283507474504267,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'yicubzho': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2914184256950586,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0006168398482204149,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'oieua62y': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.21120024573121093,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008596489897710801,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7ht70vlg': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23855171318587853,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00024264423233795452,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2matqs0f': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1032038833677,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0005105525061353309,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '100qjyxs': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1017308949425268,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 2.5361723483315e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'q37m37uz': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17524914841752534,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 1.3224017058944826e-06,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '29eu19bm': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.15659396897547273,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008605323500080865,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ce57u94g': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1316016734592294,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008355947531424496,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'n7vo46q6': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2050536116756755,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007701338458152773,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8wzblws2': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1614514831945373,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00022227307120067095,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '5e45aurd': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14393311221855826,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0005150403707110832,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9j2ihtkh': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13629631126661773,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007214244469720608,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9643pivy': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.239449652988266,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00037080989712884825,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'lqol8fmo': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2346408451678245,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00082910560695628,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2s5lgg5h': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2433234931720276,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00027404127921832835,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ek93v82t': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.16049795058360808,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.000493177039682876,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8ngt4hwg': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17977818443123902,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00029739226013204704,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'e7pccu76': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1903007943539346,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008716143970294984,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'kts1h5xf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13516030384111574,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0004024328542269946,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'cy68rqaa': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2898902606961598,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0006370559391156643,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'lanxs1z0': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1314181874057887,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0002475844212798116,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8u7zo5fd': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.16406696781765723,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0007334045238873742,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7wvj11dh': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2202738001564549,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0009838889880744756,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '0s44sabe': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.21275557175368104,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0002826832772802751,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rjmpj54w': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2643072751567912,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00032456241476059276,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'h5km9t5p': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2917229897239493,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0006212872548234598,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'lrubl0th': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1588466270932432,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008304901352555321,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'j085j3tr': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2849278818171441,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0009571848825636564,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'qbtxax27': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.11623049283371788,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0002180525476701356,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'm8ceddvv': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1770592064657544,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0003380683887626883,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'u9xd4jpq': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 80,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1760438249109487,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0004414024720606596,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rm316933': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.10571859201372308,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.0008259333425271607,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'k4un2seg': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18812788834736385,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'drone_example',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/drone_example/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/drone_example/weights.pkl',\n",
              "  'learning_rate': 0.00051500095746108,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'aku0py72': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2076909937956049,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.00034162363884589355,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '16agieiu': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18138908332735712,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'feedback_bloom',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/feedback_bloom/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/feedback_bloom/weights.pkl',\n",
              "  'learning_rate': 0.0004982693386230584,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'qbbqzxsu': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.27706474417368054,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0002539011069356524,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'me1o4o0n': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1693490632915518,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0002764143272495516,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'w7d0ciiv': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23421827686253152,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 5.742642272325027e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'i6fkj020': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.22890345587004424,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0003913128602389038,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'wppepbmy': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2945095590429705,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0009135889104694108,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'xjfqwbn9': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14634910834286508,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00010912928357494545,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'p0xrdbhn': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2655889791454583,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0006957714498345671,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '50hxrq1u': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.169642513424277,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0007981702875390946,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'lxg480rf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.25420508119670215,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005201742278771364,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'tlrvv08t': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.15078067439019666,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0006018700347437111,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7gxqitbr': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.287130889151688,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005303454176533573,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'vngul0kg': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1549910452098978,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 9.06714355577043e-06,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2uuu2iq0': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2793781212425423,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005619317552080827,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'mq4vvlcw': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.21337755742988285,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 2.244558761331017e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'dsnjplbm': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2568403188811882,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005669728772313863,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'vr6thcmm': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.11330632166616342,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0002189220067769845,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'rwt0td37': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.20216059241475423,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00060253591944403,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '1ez3zta2': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.18031505974553264,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0009117736297076736,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '3egjreh5': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13811466718213597,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0005525510241206019,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'x46ov0fl': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23280820130427465,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 5.3565774169448965e-05,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8qrn7lg1': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 76,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2019862093594661,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.00035589368188430003,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '4p4hyduk': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.11534111592003808,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.000508803782195644,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'awaen0te': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1868305731830645,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'experiment': 'multiphonics',\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': 'src/dataset/data/0814/multiphonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/multiphonics/weights.pkl',\n",
              "  'learning_rate': 0.0008827722112012347,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'v0i1bb6l': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.253375628304945,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'pizzicato_harmonics',\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': 'src/dataset/data/0814/pizzicato_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/pizzicato_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.0008481797083061749,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'qva04qmf': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 150,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2082541743548858,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_minidataset',\n",
              "  'seq_len': 1024,\n",
              "  'tf_type': 'timelin',\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'experiment': 'waveset_harmonics',\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0814/waveset_harmonics/processed.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0814/waveset_harmonics/weights.pkl',\n",
              "  'learning_rate': 0.00047090399635498094,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0}}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_configs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# select 5 top models from every experiment\n",
        "experiments = [\"drone_example\", \"feedback_bloom\", \"multiphonics\", \"pizzicato_harmonics\", \"waveset_harmonics\"]\n",
        "\n",
        "exp_runs = {exp: [] for exp in experiments}\n",
        "for exp in experiments:\n",
        "    # get all runs for experiment\n",
        "    for run in run_ids:\n",
        "        if all_configs[run][\"experiment\"] == exp:\n",
        "            exp_runs[exp].append(run)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get top 5 runs for each experiment\n",
        "\n",
        "_train_losses = {}\n",
        "for _id in run_ids:\n",
        "    _train_losses[_id] = json.load(open(f'{_path}/transformer_run_{_id}_{id_ep[_id]}_metrics.json'))[\"train_loss\"]\n",
        "    \n",
        "top_runs = {exp: [] for exp in experiments}\n",
        "for exp in experiments:\n",
        "    # sort runs by train_loss\n",
        "    sorted_runs = sorted(exp_runs[exp], key=lambda x: _train_losses[x])\n",
        "    top_runs[exp] = sorted_runs[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'drone_example': ['7jek9blg', 'xt1b5ncs', 'tbimy590', 'kdfu69md', 'ov2quu9v'],\n",
              " 'feedback_bloom': ['21soegq8',\n",
              "  '0lhbjjox',\n",
              "  '1qvcwtuy',\n",
              "  'b4gmn89t',\n",
              "  'jw8cws22'],\n",
              " 'multiphonics': ['rarx6o1s', 'qfqaf3a0', '5qndphh8', 'a9wnfeis', 'awaen0te'],\n",
              " 'pizzicato_harmonics': ['8wzblws2',\n",
              "  '2s5lgg5h',\n",
              "  'e7pccu76',\n",
              "  'u9xd4jpq',\n",
              "  '7wvj11dh'],\n",
              " 'waveset_harmonics': ['56lvlmuj',\n",
              "  'gza0sltm',\n",
              "  'r21hwu9p',\n",
              "  '7f4fvk0u',\n",
              "  'rlx8q7wd']}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# top runs ordered by asc loss\n",
        "all_top_runs = [run for exp in experiments for run in top_runs[exp]]\n",
        "top_runs_ordered_by_asc_loss = sorted(all_top_runs, key=lambda x: _train_losses[x])\n",
        "\n",
        "# save top runs ordered by asc loss\n",
        "filename = _path + \"/top-runs/models_ordered_by_asc_loss.json\"\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(top_runs_ordered_by_asc_loss, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# copy to runs to new folder\n",
        "import shutil\n",
        "\n",
        "for exp in experiments:\n",
        "    for run in top_runs[exp]:\n",
        "        src_model = f'{_path}/transformer_run_{run}_{id_ep[run]}.model'\n",
        "        src_config = f'{_path}/transformer_run_{run}_{id_ep[run]}.json'\n",
        "        src_metrics = f'{_path}/transformer_run_{run}_{id_ep[run]}_metrics.json'\n",
        "        \n",
        "        dest_model = f'{_path}/top-runs/transformer_run_{run}_{id_ep[run]}.model'\n",
        "        dest_config = f'{_path}/top-runs/transformer_run_{run}_{id_ep[run]}.json'\n",
        "        dest_metrics = f'{_path}/top-runs/transformer_run_{run}_{id_ep[run]}_metrics.json'\n",
        "        \n",
        "        os.makedirs(os.path.dirname(dest_model), exist_ok=True)\n",
        "        shutil.copy(src_model, dest_model)\n",
        "        shutil.copy(src_config, dest_config)\n",
        "        shutil.copy(src_metrics, dest_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "#id_ep for top runs\n",
        "top_runs_id_ep = {run: id_ep[run] for exp in experiments for run in top_runs[exp]}\n",
        "filename = _path + \"/top-runs/id_ep.json\"\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(top_runs_id_ep, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run ids for top runs\n",
        "top_run_ids = []\n",
        "for exp in experiments:\n",
        "    for run in top_runs[exp]:\n",
        "        top_run_ids.append(run)\n",
        "\n",
        "filename = _path + \"/top-runs/run_ids.json\"\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(top_run_ids, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# scaled params for top runs\n",
        "scaled_model_coordinates_top_runs = {run: scaled_model_coordinates[run] for exp in experiments for run in top_runs[exp]}\n",
        "\n",
        "filename = _path + \"/top-runs/scaled_params.json\"\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(scaled_model_coordinates_top_runs, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "#copy 5 random runs from each experiment \n",
        "\n",
        "import random\n",
        "random_runs = {exp: [] for exp in experiments}\n",
        "\n",
        "# select 5 random runs from each experiment\n",
        "for exp in experiments:\n",
        "    random_runs[exp] = random.sample(exp_runs[exp], 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# copy to runs to new folder\n",
        "import shutil\n",
        "\n",
        "for exp in experiments:\n",
        "    for run in random_runs[exp]:\n",
        "        src_model = f'{_path}/all/transformer_run_{run}_{id_ep[run]}.model'\n",
        "        src_config = f'{_path}/all/transformer_run_{run}_{id_ep[run]}.json'\n",
        "        src_metrics = f'{_path}/all/transformer_run_{run}_{id_ep[run]}_metrics.json'\n",
        "        \n",
        "        dest_model = f'{_path}/random-runs/transformer_run_{run}_{id_ep[run]}.model'\n",
        "        dest_config = f'{_path}/random-runs/transformer_run_{run}_{id_ep[run]}.json'\n",
        "        dest_metrics = f'{_path}/random-runs/transformer_run_{run}_{id_ep[run]}_metrics.json'\n",
        "        \n",
        "        os.makedirs(os.path.dirname(dest_model), exist_ok=True)\n",
        "        \n",
        "        shutil.copy(src_model, dest_model)\n",
        "        shutil.copy(src_config, dest_config)\n",
        "        shutil.copy(src_metrics, dest_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# random runs ordered by asc loss\n",
        "all_random_runs = [run for exp in experiments for run in random_runs[exp]]\n",
        "random_runs_ordered_by_asc_loss = sorted(all_random_runs, key=lambda x: _train_losses[x])\n",
        "\n",
        "# save random runs ordered by asc loss\n",
        "filename = _path + \"/random-runs/models_ordered_by_asc_loss.json\"\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(random_runs_ordered_by_asc_loss, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "#id_ep for random runs\n",
        "random_runs_id_ep = {run: id_ep[run] for exp in experiments for run in random_runs[exp]}\n",
        "filename = _path + \"/random-runs/id_ep.json\"\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(random_runs_id_ep, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# scaled params for random runs\n",
        "scaled_model_coordinates_random_runs = {run: scaled_model_coordinates[run] for exp in experiments for run in random_runs[exp]}\n",
        "\n",
        "filename = _path + \"/random-runs/scaled_params.json\"\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(scaled_model_coordinates_random_runs, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'drone_example': ['x086wfiq', 'u3gpoeb5', 'tbimy590', 'tcsffrxh', 'kdfu69md'],\n",
              " 'feedback_bloom': ['b70ksuej',\n",
              "  'jw8cws22',\n",
              "  'zpiylfsf',\n",
              "  'z4q6c7dy',\n",
              "  '49a2ejsd'],\n",
              " 'multiphonics': ['x46ov0fl', 'j9980erp', 'rj02z1yf', 'me1o4o0n', '7gxqitbr'],\n",
              " 'pizzicato_harmonics': ['h5km9t5p',\n",
              "  'yicubzho',\n",
              "  '2s5lgg5h',\n",
              "  '0s44sabe',\n",
              "  'v0i1bb6l'],\n",
              " 'waveset_harmonics': ['c3xau2c1',\n",
              "  'lqaq5o7t',\n",
              "  'ig61duyp',\n",
              "  '1kr3jr21',\n",
              "  '7f4fvk0u']}"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run ids for random runs\n",
        "random_run_ids = []\n",
        "for exp in experiments:\n",
        "    for run in random_runs[exp]:\n",
        "        random_run_ids.append(run)\n",
        "\n",
        "filename = _path + \"/random-runs/run_ids.json\"\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(random_run_ids, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='../trained/transformer-minidataset/random-runs/transformer_run_vfq0mqr2_75.model' mode='r' encoding='UTF-8'>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "api = wandb.Api()\n",
        "api.entity = \"faab-hyperparams\"\n",
        "\n",
        "run = \"vfq0mqr2\"\n",
        "run = api.run(f\"faab-hyperparams/faab_autoencoder_minidataset/{run}\")\n",
        "root_file_name = f'transformer_run_{run.id}_{id_ep[run.id]}'\n",
        "_path = \"../trained/transformer-minidataset/random-runs\"\n",
        "run.file(f'{root_file_name}.model').download(root=_path, exist_ok=True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "faab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
